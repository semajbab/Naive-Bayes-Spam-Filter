{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes Spam Filter\n",
    "\n",
    "Today we are making an sms spam filter using the multinomial Naive Bayes algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('SMSSpamCollection', \n",
    "                 sep='\\t',\n",
    "                 header=None, \n",
    "                 names=['Label','SMS']\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding out what pctg is ham \n",
    "\n",
    "ham = df[df['Label']=='ham'].sum()\n",
    "\n",
    "p_ham = len(ham) / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training\n",
    "\n",
    "Before we write our filter, we must split the data into training and test data so that we can verify that it works in the way it's supposed to. \n",
    "\n",
    "Our training set will contain ~80% of the data. \n",
    "\n",
    "Our test set will contain the remaining ~20%. \n",
    "\n",
    "An important fact to notice is that 20% of the data we have has been classified by a human, we are going to use this to compare against our filter when we are done writing it. \n",
    "\n",
    "Our goal with this filter is for it to correctly classify more than 80% of the spam messages as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "#lets randomize the entire set to start\n",
    "\n",
    "#I think we can skip the below step if we use the sample method like we \n",
    "#did farther down\n",
    "\n",
    "    #df = df.sample(frac=1, random_state=1)\n",
    "    #these two params \n",
    "        #randomize the entire dataset \n",
    "        #ensure our results are reproducible\n",
    "    \n",
    "#now we must split the dataset into training and test \n",
    "\n",
    "train = df.sample(frac=.8, random_state=1).reset_index(drop=True)\n",
    "\n",
    "#notice how we didnt use sample here also or else we could have populated \n",
    "#the testing set with some of the same values as the training set\n",
    "test = df.drop(train.index).reset_index(drop=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.869838\n",
       "spam    0.130162\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.86541\n",
       "spam    0.13459\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above mixtures of ham to spam are similar to our main dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "\n",
    "Let's bring the data into a useable format!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       Yep, by the pretty sculpture\n",
       "1   ham      Yes, princess. Are you going to make me moan?\n",
       "2   ham                         Welp apparently he retired\n",
       "3   ham                                            Havent.\n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we want to replace the SMS column with a series of columns that capture\n",
    "#each word from our vocabulary\n",
    "\n",
    "#lets first strip every col of punctuation\n",
    "    #using the vectorized string method .str.replace() along with the \n",
    "    #regex \\W to get rid of punctuation\n",
    "    \n",
    "train['SMS'] = train['SMS'].str.replace('\\W', ' ')\n",
    "\n",
    "#using vectorized string method .str.lower() to convert to lower case\n",
    "train['SMS'] = train['SMS'].str.lower()\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we can create our vocab\n",
    "\n",
    "#first we transform each msg from SMS into a list\n",
    "    #can do this by split string at space char \n",
    "    #note: the method already splits on whitespace so we dont have to pass it anything\n",
    "\n",
    "train['SMS'] = train['SMS'].str.split()\n",
    "\n",
    "vocabulary = []\n",
    "\n",
    "for msg in train['SMS']:\n",
    "    \n",
    "    for word in msg: \n",
    "        \n",
    "        vocabulary.append(word)\n",
    "    \n",
    "#now transform the vocab list into a set using set()\n",
    "    #this removes the duplicates \n",
    "    \n",
    "vocabulary = set(vocabulary)\n",
    "\n",
    "#now transform vocab list back into list using list()\n",
    "\n",
    "vocabulary = list(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7783\n"
     ]
    }
   ],
   "source": [
    "#lets check the length of our vocab \n",
    "\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! looks like we have almost 800 unique words in our vocabulary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now we are going to use our vocab to create those enumerated columns we wanted\n",
    "\n",
    "#lets start by creating a dictionary\n",
    "\n",
    "    #in this dictionary the keys are the words from our vocab (remember they're all unique because we turned the list into a set)\n",
    "    \n",
    "    #the values are lists the length of the training set with each element equal to zero\n",
    "        #the values are lists because we are using a list comprehension... hence the 'for...' in our dictionary\n",
    "        \n",
    "word_counts = {vocab_word: [0] * len(train['SMS']) for vocab_word in vocabulary}\n",
    "\n",
    "#now we can loop thru our training data... \n",
    "    #at the end we increment the value corresponding to the word in our dictionary by 1 \n",
    "for index, sms in enumerate(train['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts[word][index] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>02072069400</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  00  000  000pes  008704050406  0089  01223585334  02  0207  02072069400  \\\n",
       "0  0   0    0       0             0     0            0   0     0            0   \n",
       "1  0   0    0       0             0     0            0   0     0            0   \n",
       "2  0   0    0       0             0     0            0   0     0            0   \n",
       "3  0   0    0       0             0     0            0   0     0            0   \n",
       "4  0   0    0       0             0     0            0   0     0            0   \n",
       "\n",
       "  ...  zindgi  zoe  zogtorius  zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "1 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "2 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "3 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "4 ...       0    0          0     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turning the above dictionary into a df \n",
    "\n",
    "word_counts = pd.DataFrame(word_counts)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  0  00  000  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]  0   0    0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...  0   0    0   \n",
       "2   ham                    [welp, apparently, he, retired]  0   0    0   \n",
       "3   ham                                           [havent]  0   0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...  0   0    0   \n",
       "\n",
       "   000pes  008704050406  0089  01223585334  02 ...  zindgi  zoe  zogtorius  \\\n",
       "0       0             0     0            0   0 ...       0    0          0   \n",
       "1       0             0     0            0   0 ...       0    0          0   \n",
       "2       0             0     0            0   0 ...       0    0          0   \n",
       "3       0             0     0            0   0 ...       0    0          0   \n",
       "4       0             0     0            0   0 ...       0    0          0   \n",
       "\n",
       "   zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0     0      0  0   0  0    0  0  \n",
       "1     0      0  0   0  0    0  0  \n",
       "2     0      0  0   0  0    0  0  \n",
       "3     0      0  0   0  0    0  0  \n",
       "4     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we must combine the new dataframe from above with our training data so we can use it\n",
    "\n",
    "train_final = pd.concat([train, word_counts], axis=1)\n",
    "train_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating The Spam Filter\n",
    "\n",
    "Now that our training data is prepared we can train our spam filter!\n",
    "\n",
    "Lets first review our main equations...\n",
    "\n",
    "\n",
    "$P(Spam|w_{1},w_{2},...,w_{n})\\alpha P(Spam)\\cdot \\prod_{i=1}^{n}P(w_{i}|Spam)$\n",
    "\n",
    "$P(Ham|w_{1},w_{2},...,w_{n}) \\alpha P(Ham)\\cdot \\prod_{i=1}^{n}P(w_{i}|Ham)$\n",
    "\n",
    "And the equations for the parameters...\n",
    "\n",
    "$P(w_{i}|Spam)=\\frac{N_{w_{i}|Spam}+α}{N_{Spam}+α⋅N_{Vocabulary}}$\n",
    "\n",
    "$P(w_{i}|Ham)=\\frac{N_{w_{i}|Ham}+α}{N_{Ham}+α⋅N_{Vocabulary}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "#lets calulate some of the variables in our equations for the spam filter\n",
    "    #to see these two equations (complete with additive smoothing) check the \n",
    "    #Naive Bayes notes in dataquest folder\n",
    "\n",
    "    \n",
    "#we need to find out how many msgs are spam using a loop \n",
    "    #we can then take this away from the total len of msgs to find numb of non spam msgs\n",
    "\n",
    "spam_msg = 0 \n",
    "\n",
    "for msg in train_final['Label']: \n",
    "    \n",
    "    if msg == 'spam': \n",
    "        spam_msg += 1 \n",
    "\n",
    "print(spam_msg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the probability a msg is spam: 0.13\n",
      "this is the probability a msg is not spam: 0.87\n"
     ]
    }
   ],
   "source": [
    "#this is the probability that a new message is spam\n",
    "p_spam = spam_msg / len(train_final)\n",
    "\n",
    "#this is the probability that a new message is NOT spam\n",
    "p_ham = (len(train_final) - spam_msg) / len(train_final)\n",
    "\n",
    "print(\"this is the probability a msg is spam:\", round(p_spam, 2))\n",
    "print(\"this is the probability a msg is not spam:\", round(p_ham, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now we want the n_spam value \n",
    "    #this value is the total words there are in all spam messages\n",
    "    \n",
    "    #we can first isolate the spam messages\n",
    "    \n",
    "spam_msgs = train_final[train_final['Label'] == 'spam']\n",
    "\n",
    "    #now we can apply the len function to the sms column to count the elements in each list\n",
    "    #this will result in a list that we have to sum \n",
    "    \n",
    "numb_words_per_spam_msg = spam_msgs['SMS'].apply(len)\n",
    "n_spam = numb_words_per_spam_msg.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now we can do the same things but with non-spam msgs\n",
    "\n",
    "ham_msgs = train_final[train_final['Label'] == 'ham']\n",
    "\n",
    "\n",
    "numb_words_per_non_spam_msg = ham_msgs['SMS'].apply(len)\n",
    "n_ham = numb_words_per_non_spam_msg.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to find the number of words in our vocab all we have to do is add \n",
    "#n_spam and n_ham \n",
    "\n",
    "n_vocab = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we also must define our alpha parameter for additive smoothing \n",
    "\n",
    "alpha = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 15190 \n",
      " 57237 \n",
      " 7783\n"
     ]
    }
   ],
   "source": [
    "#lastly lets print all these constants off \n",
    "\n",
    "print('\\n', n_spam, '\\n', n_ham, '\\n', n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick sanity check... these values seem reasonable! We can now move on to calculating our parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**\n",
    "\n",
    "Now that our constants are calculated we can move on to calculating our parameters. \n",
    "\n",
    "Recall...\n",
    "\n",
    "$P(w_{i}|Spam)=\\frac{N_{w_{i}|Spam}+α}{N_{Spam}+α⋅N_{Vocabulary}}$\n",
    "\n",
    "$P(w_{i}|Ham)=\\frac{N_{w_{i}|Ham}+α}{N_{Ham}+α⋅N_{Vocabulary}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00021764680276846734, 4.3529360553693465e-05, 4.3529360553693465e-05, 4.3529360553693465e-05, 4.3529360553693465e-05]\n"
     ]
    }
   ],
   "source": [
    "#it's time to calculate our params \n",
    "    #these are the probabilities that P(wi|Spam) and P(wi|Ham) are going to take\n",
    "\n",
    "#initializing two dicts to store our params\n",
    "\n",
    "p_wi_spam = {} \n",
    "p_wi_ham = {}\n",
    "\n",
    "    #we are going to fill these dicts with the entire vocab and each value set to 0 \n",
    "    \n",
    "for word in vocabulary: \n",
    "    \n",
    "    p_wi_spam[word] = 0 \n",
    "    p_wi_ham[word] = 0\n",
    "\n",
    "#note that spam and ham messages have already been split into two dfs from when we calculated constants\n",
    "\n",
    "#iterating thru the VOCAB!!! (not the training data), calculating P(wi|Spam) and P(wi|Ham), and assigning to relevant dicts\n",
    "for word in vocabulary: \n",
    "    \n",
    "    #recall N_wi|spam is the number of times the word wi occurs in all spam messages\n",
    "    #the same logic applies for N_wi|ham\n",
    "    \n",
    "    n_wi_spam = spam_msgs[word].sum()\n",
    "    p_wi_spam[word] = (n_wi_spam + alpha) / (n_spam + alpha * n_vocab)\n",
    "    \n",
    "    n_wi_ham = ham_msgs[word].sum()\n",
    "    p_wi_ham[word] = (n_wi_ham + alpha) / (n_ham + alpha * n_vocab)\n",
    "    \n",
    "#we can grab a few parameter values from the p_wi_spam dict\n",
    "x=list(p_wi_spam.values())\n",
    "\n",
    "print(x[0:5])\n",
    "\n",
    "#seems to work..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing\n",
    "\n",
    "We've just calculated all the constants and parameters we will need. Now we'd like to put this filter to the test by classifying a new message. \n",
    "\n",
    "From the lesson: \n",
    "\n",
    "The spam filter can be understood as a function that:\n",
    "\n",
    "- Takes in as input a new message (w1, w2, ..., wn)\n",
    "- Calculates P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn)\n",
    "- Compares the values of P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn), and:\n",
    "- If P(Ham|w1, w2, ..., wn) > P(Spam|w1, w2, ..., wn), then the message is classified as ham.\n",
    "- If P(Ham|w1, w2, ..., wn) < P(Spam|w1, w2, ..., wn), then the message is classified as spam.\n",
    "- If P(Ham|w1, w2, ..., wn) = P(Spam|w1, w2, ..., wn), then the algorithm may request human help.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message) #remember \\W matches a word character so here we are removing punctuation\n",
    "    message = message.lower() \n",
    "    message = message.split() #splitting at space char and transforming the string into a list\n",
    "\n",
    "    \n",
    "    #these are just the main equations we listed above \n",
    "    \n",
    "        #initate with a value -- we are going to use our constants\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "        #now iterate through message and include the appropriate values into\n",
    "        #the above equations\n",
    "        \n",
    "    for word in message: \n",
    "        \n",
    "        if word in p_wi_spam:\n",
    "            #if in the vocab we need to include it in our equation above\n",
    "            p_spam_given_message *= p_wi_spam[word] #the *= multiplies with left operand and assigns val to left operand\n",
    "            \n",
    "        if word in p_wi_ham:\n",
    "            #same logic as above \n",
    "            p_ham_given_message *= p_wi_ham[word]\n",
    "            \n",
    "        else:\n",
    "            pass \n",
    "       \n",
    "    #this code below compares the results and classifies our result\n",
    "    \n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n",
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "#now lets test it with a few phrases...\n",
    "\n",
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')\n",
    "\n",
    "classify(\"Sounds good, Tom, then see u there\")\n",
    "\n",
    "\n",
    "#weeee it works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Accuracy\n",
    "\n",
    "We would now like to see how accurate our spam filter is. This is going to involve us using the testing data we split off at the beginning of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first we are going to change our spam filter to return the labels rather than print them... \n",
    "\n",
    "\n",
    "def classify_test(message):\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message) #remember \\W matches a word character so here we are removing punctuation\n",
    "    message = message.lower() \n",
    "    message = message.split() #splitting at space char and transforming the string into a list\n",
    "\n",
    "    \n",
    "    #these are just the main equations we listed above \n",
    "    \n",
    "        #initate with a value -- we are going to use our constants\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "        #now iterate through message and include the appropriate values into\n",
    "        #the above equations\n",
    "        \n",
    "    for word in message: \n",
    "        \n",
    "        if word in p_wi_spam:\n",
    "            #if in the vocab we need to include it in our equation above\n",
    "            p_spam_given_message *= p_wi_spam[word] #the *= multiplies with left operand and assigns val to left operand\n",
    "            \n",
    "        if word in p_wi_ham:\n",
    "            #same logic as above \n",
    "            p_ham_given_message *= p_wi_ham[word]\n",
    "            \n",
    "        else:\n",
    "            pass \n",
    "    \n",
    "    #notice we are changing this portion of the code to return strings so that we can \n",
    "    #evaluate the accuracy of our classifier against the labeled testing data\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'ask human'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aight should I just plan to come up later toni...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Die... I accidentally deleted e msg i suppose ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Welcome to UK-mobile-date this msg is FREE giv...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Thanks again for your reply today. When is ur ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predictions\n",
       "0   ham  Aight should I just plan to come up later toni...         ham\n",
       "1   ham  Die... I accidentally deleted e msg i suppose ...         ham\n",
       "2  spam  Welcome to UK-mobile-date this msg is FREE giv...        spam\n",
       "3   ham  This is wishing you a great day. Moji told me ...         ham\n",
       "4   ham  Thanks again for your reply today. When is ur ...         ham"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets add a column to our test data so that we can store the newly classified values\n",
    "\n",
    "test['predictions'] = test['SMS'].apply(classify_test) #applying our test funciton that returns values\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks promising... lets measure the accuracy using the following formula: \n",
    "\n",
    "Accuracy = # correctly classified messages / # incorrectly classified messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9910233393177738\n",
      "Wrong: 10\n",
      "Total 1114\n"
     ]
    }
   ],
   "source": [
    "correct = 0 \n",
    "total = len(test)\n",
    "\n",
    "#we are iterating over each row in our df using .iterrows()\n",
    "#for each row we are checking if the label and predictions values match \n",
    "    #if they do we are increasing our value of correct\n",
    "    \n",
    "for row in test.iterrows():\n",
    "    #selecting the row in our iterable 'row' --> this is because iterrows returns index series pairs \n",
    "    row = row[1]\n",
    "    \n",
    "    if row['Label'] == row['predictions']:\n",
    "        correct += 1 \n",
    "        \n",
    "print('Accuracy:', correct / total)\n",
    "print('Wrong:', total - correct)\n",
    "print('Total', total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! What an impressive result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
